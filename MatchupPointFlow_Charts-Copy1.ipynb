{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Agg')  #Fixing AWS Lambda MPL backend issue\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as md\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.io.json import json_normalize\n",
    "from datetime import datetime,date,timedelta\n",
    "import boto3\n",
    "import pytz \n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import io\n",
    "\n",
    "params = {\n",
    "'token' : 'jgyuNE4NXwPdjzmQS568me3TyXLAL9ZCU9NkVlKj'\n",
    ",'bot_id' :'4e93908dd6e03b66cbd07fc458' #Test\n",
    "}\n",
    "\n",
    "dynamodb = boto3.resource('dynamodb')\n",
    "table = dynamodb.Table('MatchupGameFlow')\n",
    "\n",
    "leagueId = '111414'\n",
    "season = datetime.now().astimezone(pytz.timezone('US/Eastern')).year\n",
    "\n",
    "r = requests.get('http://www.nfl.com/liveupdate/scorestrip/ss.xml')\n",
    "schedxml = BeautifulSoup(r.text, \"html.parser\")\n",
    "#week = schedxml.find('gms')['w']\n",
    "week = 'P1'\n",
    "\n",
    "def _is_nfl_game_active():\n",
    "    r = requests.get('http://www.nfl.com/liveupdate/scorestrip/ss.xml')\n",
    "    schedxml = BeautifulSoup(r.text, \"html.parser\")\n",
    "    active = False\n",
    "    for info in schedxml.findAll('g'):        \n",
    "        gamestatus = info['q']\n",
    "        if(gamestatus != 'F'  and gamestatus != 'FO' and gamestatus != 'P'):\n",
    "            active = True  \n",
    "            break\n",
    "        \n",
    "    return active # return active\n",
    "\n",
    "#_is_nfl_game_active()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-13 20:20:00-05:00\n",
      "2018-12-15 16:30:00-05:00\n",
      "2018-12-15 20:20:00-05:00\n",
      "2018-12-16 13:00:00-05:00\n",
      "2018-12-16 13:00:00-05:00\n",
      "2018-12-16 13:00:00-05:00\n",
      "2018-12-16 13:00:00-05:00\n",
      "2018-12-16 13:00:00-05:00\n",
      "2018-12-16 13:00:00-05:00\n",
      "2018-12-16 13:00:00-05:00\n",
      "2018-12-16 13:00:00-05:00\n",
      "2018-12-16 13:00:00-05:00\n",
      "2018-12-16 16:05:00-05:00\n",
      "2018-12-16 16:25:00-05:00\n",
      "2018-12-16 20:20:00-05:00\n",
      "2018-12-17 20:15:00-05:00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _last_game_ended_recently():\n",
    "    r = requests.get('http://www.nfl.com/liveupdate/scorestrip/ss.xml')\n",
    "    schedxml = BeautifulSoup(r.text, \"html.parser\")\n",
    "\n",
    "#    current_utc_ts = pytz.utc.localize(datetime(2018, 11, 5, 18, 59))\n",
    "    current_utc_ts = pytz.utc.localize(datetime.utcnow())\n",
    "    last_game_end_utc_ts = pytz.utc.localize(datetime(2000, 1, 1, 0, 0))\n",
    "    local_tz = pytz.timezone('US/Eastern')\n",
    "\n",
    "    for info in schedxml.findAll('g'):\n",
    "        hour, minute = info['t'].strip().split(':')\n",
    "        d = local_tz.localize(datetime(int(info['eid'][:4]), int(info['eid'][4:6]), int(info['eid'][6:8]),\n",
    "                              (int(hour) + 12) % 24, int(minute))) \n",
    "        print(d)\n",
    "        if(d.hour == 21 and d.minute == 30): #Saturday 9:30am games need to be adjusted from PM to AM\n",
    "            d = d - timedelta(hours=12)\n",
    "        \n",
    "        \n",
    "        start_utc = d.astimezone(pytz.timezone('UTC')) #convert to UTC for AWS Lambda environment\n",
    "        end_utc = d.astimezone(pytz.timezone('UTC')) + timedelta(hours=4.5) #convert to UTC for AWS Lambda environment\n",
    "\n",
    "        #print(current_utc_ts,start_utc,end_utc,current_utc_ts >= start_utc and current_utc_ts <= end_utc )\n",
    "        if(current_utc_ts >= start_utc and current_utc_ts <= end_utc):\n",
    "            return True        \n",
    "\n",
    "    return False\n",
    "\n",
    "_last_game_ended_recently()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def generate_charts():\n",
    "    data = table.scan()\n",
    "\n",
    "    df = json_normalize(data, 'Items')[['COLLECTTIMESTAMP','TEAM1','TEAM1NAME','TEAM1PTS','TEAM1PROJ','TEAM2NAME','TEAM2PTS','TEAM2PROJ','SCORINGPERIOD']]\n",
    "    df = df[df['SCORINGPERIOD']==week].sort_values('COLLECTTIMESTAMP', ascending=True)\n",
    "    #df[['COLLECTTIMESTAMP']] = df[['COLLECTTIMESTAMP']].apply(pd.to_datetime)  # commenting removes attempt at date labels on x-axis\n",
    "    df[['TEAM1PTS','TEAM1PROJ','TEAM2PTS','TEAM2PROJ']] = df[['TEAM1PTS','TEAM1PROJ','TEAM2PTS','TEAM2PROJ']].apply(pd.to_numeric)\n",
    "\n",
    "\n",
    "    imgs = []\n",
    "    for home_team in df['TEAM1NAME'].unique():\n",
    "        matchup = df[df['TEAM1NAME']==home_team]\n",
    "        team1 = matchup['TEAM1NAME'].unique()[0]\n",
    "        team2 = matchup['TEAM2NAME'].unique()[0]\n",
    "\n",
    "        fig, ax = plt.subplots(1,1)\n",
    "\n",
    "        plt.title(team1+' vs. '+team2+'\\nWeek '+week)\n",
    "        #ax.xaxis.set_minor_locator(md.HourLocator(interval=4))   # every 4 hours\n",
    "        #ax.xaxis.set_minor_formatter(md.DateFormatter('%H:%M'))  # hours and minutes\n",
    "        #ax.xaxis.set_major_locator(md.HourLocator(interval=12))    # every day\n",
    "        #ax.xaxis.set_major_formatter(md.DateFormatter('\\n%a'))\n",
    "        #ax.set_xlim(datetime(2018, 10, 1, 20), datetime(2018, 10, 2 , 0))\n",
    "        ax.xaxis.set_major_locator(plt.NullLocator())\n",
    "        \n",
    "        line_t1pts, = ax.plot(matchup['COLLECTTIMESTAMP'], matchup['TEAM1PTS'], 'r', label=matchup['TEAM1NAME'].unique()[0]+' PTS')\n",
    "        line_t1proj, = ax.plot(matchup['COLLECTTIMESTAMP'], matchup['TEAM1PROJ'], 'r',linestyle='--', dashes=(2, 2), label=matchup['TEAM1NAME'].unique()[0]+' PROJ')\n",
    "        line_t2pts, = ax.plot(matchup['COLLECTTIMESTAMP'], matchup['TEAM2PTS'], 'b', label=matchup['TEAM2NAME'].unique()[0]+' PTS')\n",
    "        line_t2proj, = ax.plot(matchup['COLLECTTIMESTAMP'], matchup['TEAM2PROJ'], 'b',linestyle='--', dashes=(2, 2), label=matchup['TEAM2NAME'].unique()[0]+' PROJ')\n",
    "        ax.legend(loc='best')\n",
    "\n",
    "        buf = io.BytesIO()\n",
    "        plt.savefig(buf, format='png')\n",
    "        buf.seek(0)\n",
    "        imgs.append(buf)\n",
    "        #plt.show()\n",
    "        plt.close()\n",
    "    return imgs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def post_to_groupme(input, imgs):\n",
    "    headers_img = {\n",
    "        'X-Access-Token': input['token'],\n",
    "        'Content-Type': 'image/jpeg',\n",
    "    }\n",
    "\n",
    "    headers_post = {\n",
    "        'Content-Type': 'application/json',\n",
    "    }\n",
    "\n",
    "    for img in imgs:\n",
    "        img.seek(0)\n",
    "        img = requests.post('https://image.groupme.com/pictures', headers=headers_img, data=img)\n",
    "        imgurl = img.json()['payload']['picture_url']\n",
    "        data = '{\"bot_id\":\"'+input['bot_id']+'\",\"text\":\"\",\"attachments\":[{\"type\":\"image\",\"url\":\"'+imgurl+'\"}]}'\n",
    "        response = requests.post('https://api.groupme.com/v3/bots/post', headers=headers_post, data=data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lambda_handler(input,context):\n",
    "    if not _is_nfl_game_active() and not _last_game_ended_recently():\n",
    "        return False\n",
    "    \n",
    "    post_to_groupme(input, generate_charts())\n",
    "    return True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    data = table.scan()\n",
    "\n",
    "    df = json_normalize(data, 'Items')\n",
    "#    df = json_normalize(data, 'Items')[['COLLECTTIMESTAMP','TEAM1','TEAM1NAME','TEAM1PTS','TEAM1PROJ','TEAM2NAME','TEAM2PTS','TEAM2PROJ','SCORINGPERIOD']]\n",
    "    df = df[df['SCORINGPERIOD']==week].sort_values('COLLECTTIMESTAMP', ascending=True)\n",
    "    #df[['COLLECTTIMESTAMP']] = df[['COLLECTTIMESTAMP']].apply(pd.to_datetime)  # commenting removes attempt at date labels on x-axis\n",
    "#    df[['TEAM1PTS','TEAM1PROJ','TEAM2PTS','TEAM2PROJ']] = df[['TEAM1PTS','TEAM1PROJ','TEAM2PTS','TEAM2PROJ']].apply(pd.to_numeric)\n",
    "    return data\n",
    "\n",
    "data = get_data()\n",
    "\n",
    "#df[df['TEAM1NAME']=='Paul'].sort_values('COLLECTTIMESTAMP',ascending=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 2018-12-13 21:43:31 11 P1\n",
      "15 2018-12-13 21:43:31 12 P1\n",
      "15 2018-12-13 21:43:31 3 P1\n",
      "15 2018-12-13 21:43:31 4 P1\n",
      "15 2018-12-13 21:43:31 7 P1\n",
      "15 2018-12-13 21:43:31 8 P1\n",
      "15 2018-12-13 22:03:31 11 P1\n",
      "15 2018-12-13 22:03:31 12 P1\n",
      "15 2018-12-13 22:03:31 3 P1\n",
      "15 2018-12-13 22:03:31 4 P1\n",
      "15 2018-12-13 22:03:31 7 P1\n",
      "15 2018-12-13 22:03:31 8 P1\n",
      "15 2018-12-13 20:44:31 11 P1\n",
      "15 2018-12-13 20:44:31 12 P1\n",
      "15 2018-12-13 20:44:31 3 P1\n",
      "15 2018-12-13 20:44:31 4 P1\n",
      "15 2018-12-13 20:44:31 7 P1\n",
      "15 2018-12-13 20:44:31 8 P1\n",
      "15 2018-12-13 22:37:31 11 P1\n",
      "15 2018-12-13 22:37:31 12 P1\n",
      "15 2018-12-13 22:37:31 3 P1\n",
      "15 2018-12-13 22:37:31 4 P1\n",
      "15 2018-12-13 22:37:31 7 P1\n",
      "15 2018-12-13 22:37:31 8 P1\n",
      "15 2018-12-13 22:01:31 11 P1\n",
      "15 2018-12-13 22:01:31 12 P1\n",
      "15 2018-12-13 22:01:31 3 P1\n",
      "15 2018-12-13 22:01:31 4 P1\n",
      "15 2018-12-13 22:01:31 7 P1\n",
      "15 2018-12-13 22:01:31 8 P1\n",
      "15 2018-12-13 23:15:31 11 P1\n",
      "15 2018-12-13 23:15:31 12 P1\n",
      "15 2018-12-13 23:15:31 3 P1\n",
      "15 2018-12-13 23:15:31 4 P1\n",
      "15 2018-12-13 23:15:31 7 P1\n",
      "15 2018-12-13 23:15:31 8 P1\n",
      "15 2018-12-13 21:39:31 11 P1\n",
      "15 2018-12-13 21:39:31 12 P1\n",
      "15 2018-12-13 21:39:31 3 P1\n",
      "15 2018-12-13 21:39:31 4 P1\n",
      "15 2018-12-13 21:39:31 7 P1\n",
      "15 2018-12-13 21:39:31 8 P1\n",
      "15 2018-12-13 20:38:31 11 P1\n",
      "15 2018-12-13 20:38:31 12 P1\n",
      "15 2018-12-13 20:38:31 3 P1\n",
      "15 2018-12-13 20:38:31 4 P1\n",
      "15 2018-12-13 20:38:31 7 P1\n",
      "15 2018-12-13 20:38:31 8 P1\n",
      "15 2018-12-13 22:24:31 11 P1\n",
      "15 2018-12-13 22:24:31 12 P1\n",
      "15 2018-12-13 22:24:31 3 P1\n",
      "15 2018-12-13 22:24:31 4 P1\n",
      "15 2018-12-13 22:24:31 7 P1\n",
      "15 2018-12-13 22:24:31 8 P1\n",
      "15 2018-12-13 20:36:31 11 P1\n",
      "15 2018-12-13 20:36:31 12 P1\n",
      "15 2018-12-13 20:36:31 3 P1\n",
      "15 2018-12-13 20:36:31 4 P1\n",
      "15 2018-12-13 20:36:31 7 P1\n",
      "15 2018-12-13 20:36:31 8 P1\n",
      "15 2018-12-13 21:26:31 11 P1\n",
      "15 2018-12-13 21:26:31 3 P1\n",
      "15 2018-12-13 21:26:31 4 P1\n",
      "15 2018-12-13 21:26:31 7 P1\n",
      "15 2018-12-13 22:08:31 11 P1\n",
      "15 2018-12-13 22:08:31 12 P1\n",
      "15 2018-12-13 22:08:31 3 P1\n",
      "15 2018-12-13 22:08:31 4 P1\n",
      "15 2018-12-13 22:08:31 7 P1\n",
      "15 2018-12-13 22:08:31 8 P1\n",
      "15 2018-12-13 23:19:31 11 P1\n",
      "15 2018-12-13 23:19:31 12 P1\n",
      "15 2018-12-13 23:19:31 3 P1\n",
      "15 2018-12-13 23:19:31 4 P1\n",
      "15 2018-12-13 23:19:31 7 P1\n",
      "15 2018-12-13 23:19:31 8 P1\n"
     ]
    }
   ],
   "source": [
    "for item in data['Items']:\n",
    "    if item['WEEK_NM'] == 'P1':\n",
    "        print(item['SCORINGPERIOD'], item['COLLECTTIMESTAMP'], item['TEAM1'], item['WEEK_NM'])\n",
    "\n",
    "        response = table.update_item(\n",
    "            Key={\n",
    "                'COLLECTTIMESTAMP': item['COLLECTTIMESTAMP'],\n",
    "                'TEAM1': item['TEAM1']\n",
    "            },\n",
    "            UpdateExpression=\"set SCORINGPERIOD = :s\",\n",
    "            ExpressionAttributeValues={\n",
    "                ':s': \"15\"\n",
    "            },\n",
    "            ReturnValues=\"UPDATED_NEW\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 2018-12-13 21:43:31 11 P1\n",
      "15 2018-12-13 21:43:31 12 P1\n",
      "15 2018-12-13 21:43:31 3 P1\n",
      "15 2018-12-13 21:43:31 4 P1\n",
      "15 2018-12-13 21:43:31 7 P1\n",
      "15 2018-12-13 21:43:31 8 P1\n",
      "15 2018-12-13 22:03:31 11 P1\n",
      "15 2018-12-13 22:03:31 12 P1\n",
      "15 2018-12-13 22:03:31 3 P1\n",
      "15 2018-12-13 22:03:31 4 P1\n",
      "15 2018-12-13 22:03:31 7 P1\n",
      "15 2018-12-13 22:03:31 8 P1\n",
      "15 2018-12-13 20:44:31 11 P1\n",
      "15 2018-12-13 20:44:31 12 P1\n",
      "15 2018-12-13 20:44:31 3 P1\n",
      "15 2018-12-13 20:44:31 4 P1\n",
      "15 2018-12-13 20:44:31 7 P1\n",
      "15 2018-12-13 20:44:31 8 P1\n",
      "15 2018-12-13 22:37:31 11 P1\n",
      "15 2018-12-13 22:37:31 12 P1\n",
      "15 2018-12-13 22:37:31 3 P1\n",
      "15 2018-12-13 22:37:31 4 P1\n",
      "15 2018-12-13 22:37:31 7 P1\n",
      "15 2018-12-13 22:37:31 8 P1\n",
      "15 2018-12-13 22:01:31 11 P1\n",
      "15 2018-12-13 22:01:31 12 P1\n",
      "15 2018-12-13 22:01:31 3 P1\n",
      "15 2018-12-13 22:01:31 4 P1\n",
      "15 2018-12-13 22:01:31 7 P1\n",
      "15 2018-12-13 22:01:31 8 P1\n",
      "15 2018-12-13 23:15:31 11 P1\n",
      "15 2018-12-13 23:15:31 12 P1\n",
      "15 2018-12-13 23:15:31 3 P1\n",
      "15 2018-12-13 23:15:31 4 P1\n",
      "15 2018-12-13 23:15:31 7 P1\n",
      "15 2018-12-13 23:15:31 8 P1\n",
      "15 2018-12-13 21:39:31 11 P1\n",
      "15 2018-12-13 21:39:31 12 P1\n",
      "15 2018-12-13 21:39:31 3 P1\n",
      "15 2018-12-13 21:39:31 4 P1\n",
      "15 2018-12-13 21:39:31 7 P1\n",
      "15 2018-12-13 21:39:31 8 P1\n",
      "15 2018-12-13 20:38:31 11 P1\n",
      "15 2018-12-13 20:38:31 12 P1\n",
      "15 2018-12-13 20:38:31 3 P1\n",
      "15 2018-12-13 20:38:31 4 P1\n",
      "15 2018-12-13 20:38:31 7 P1\n",
      "15 2018-12-13 20:38:31 8 P1\n",
      "15 2018-12-13 22:24:31 11 P1\n",
      "15 2018-12-13 22:24:31 12 P1\n",
      "15 2018-12-13 22:24:31 3 P1\n",
      "15 2018-12-13 22:24:31 4 P1\n",
      "15 2018-12-13 22:24:31 7 P1\n",
      "15 2018-12-13 22:24:31 8 P1\n",
      "15 2018-12-13 20:36:31 11 P1\n",
      "15 2018-12-13 20:36:31 12 P1\n",
      "15 2018-12-13 20:36:31 3 P1\n",
      "15 2018-12-13 20:36:31 4 P1\n",
      "15 2018-12-13 20:36:31 7 P1\n",
      "15 2018-12-13 20:36:31 8 P1\n",
      "15 2018-12-13 21:26:31 11 P1\n",
      "15 2018-12-13 21:26:31 3 P1\n",
      "15 2018-12-13 21:26:31 4 P1\n",
      "15 2018-12-13 21:26:31 7 P1\n",
      "15 2018-12-13 22:08:31 11 P1\n",
      "15 2018-12-13 22:08:31 12 P1\n",
      "15 2018-12-13 22:08:31 3 P1\n",
      "15 2018-12-13 22:08:31 4 P1\n",
      "15 2018-12-13 22:08:31 7 P1\n",
      "15 2018-12-13 22:08:31 8 P1\n",
      "15 2018-12-13 23:19:31 11 P1\n",
      "15 2018-12-13 23:19:31 12 P1\n",
      "15 2018-12-13 23:19:31 3 P1\n",
      "15 2018-12-13 23:19:31 4 P1\n",
      "15 2018-12-13 23:19:31 7 P1\n",
      "15 2018-12-13 23:19:31 8 P1\n"
     ]
    }
   ],
   "source": [
    "for item in data['Items']:\n",
    "    #print(item['SCORINGPERIOD'])\n",
    "#    if item['SCORINGPERIOD'] == '15':\n",
    "    if item['WEEK_NM'] == 'P1':\n",
    "        print(item['SCORINGPERIOD'], item['COLLECTTIMESTAMP'], item['TEAM1'], item['WEEK_NM'])\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
