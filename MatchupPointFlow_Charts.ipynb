{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Agg')  #Fixing AWS Lambda MPL backend issue\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as md\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.io.json import json_normalize\n",
    "from datetime import datetime,date,timedelta\n",
    "import boto3\n",
    "import pytz \n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import io\n",
    "\n",
    "params = {\n",
    "'token' : 'jgyuNE4NXwPdjzmQS568me3TyXLAL9ZCU9NkVlKj'\n",
    ",'bot_id' :'4e93908dd6e03b66cbd07fc458' #Test\n",
    "#,'bot_id' :'da0beb9ba4b78d5a57a2ed6dd4' #Prod\n",
    "}\n",
    "\n",
    "dynamodb = boto3.resource('dynamodb')\n",
    "table = dynamodb.Table('MatchupGameFlow')\n",
    "\n",
    "leagueId = '111414'\n",
    "season = datetime.now().astimezone(pytz.timezone('US/Eastern')).year\n",
    "\n",
    "r = requests.get('http://www.nfl.com/liveupdate/scorestrip/ss.xml')\n",
    "schedxml = BeautifulSoup(r.text, \"html.parser\")\n",
    "week = schedxml.find('gms')['w']\n",
    "\n",
    "def _is_nfl_game_active():\n",
    "    r = requests.get('http://www.nfl.com/liveupdate/scorestrip/ss.xml')\n",
    "    schedxml = BeautifulSoup(r.text, \"html.parser\")\n",
    "    active = False\n",
    "    for info in schedxml.findAll('g'):        \n",
    "        gamestatus = info['q']\n",
    "        if(gamestatus != 'F'  and gamestatus != 'FO' and gamestatus != 'P'):\n",
    "            active = True  \n",
    "            break\n",
    "        \n",
    "    return active # return active\n",
    "\n",
    "#_is_nfl_game_active()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-13 20:20:00-05:00\n",
      "2018-12-14 19:25:36.340856+00:00 2018-12-14 01:20:00+00:00 2018-12-14 05:50:00+00:00 False\n",
      "2018-12-15 16:30:00-05:00\n",
      "2018-12-14 19:25:36.340856+00:00 2018-12-15 21:30:00+00:00 2018-12-16 02:00:00+00:00 False\n",
      "2018-12-15 20:20:00-05:00\n",
      "2018-12-14 19:25:36.340856+00:00 2018-12-16 01:20:00+00:00 2018-12-16 05:50:00+00:00 False\n",
      "2018-12-16 13:00:00-05:00\n",
      "2018-12-14 19:25:36.340856+00:00 2018-12-16 18:00:00+00:00 2018-12-16 22:30:00+00:00 False\n",
      "2018-12-16 13:00:00-05:00\n",
      "2018-12-14 19:25:36.340856+00:00 2018-12-16 18:00:00+00:00 2018-12-16 22:30:00+00:00 False\n",
      "2018-12-16 13:00:00-05:00\n",
      "2018-12-14 19:25:36.340856+00:00 2018-12-16 18:00:00+00:00 2018-12-16 22:30:00+00:00 False\n",
      "2018-12-16 13:00:00-05:00\n",
      "2018-12-14 19:25:36.340856+00:00 2018-12-16 18:00:00+00:00 2018-12-16 22:30:00+00:00 False\n",
      "2018-12-16 13:00:00-05:00\n",
      "2018-12-14 19:25:36.340856+00:00 2018-12-16 18:00:00+00:00 2018-12-16 22:30:00+00:00 False\n",
      "2018-12-16 13:00:00-05:00\n",
      "2018-12-14 19:25:36.340856+00:00 2018-12-16 18:00:00+00:00 2018-12-16 22:30:00+00:00 False\n",
      "2018-12-16 13:00:00-05:00\n",
      "2018-12-14 19:25:36.340856+00:00 2018-12-16 18:00:00+00:00 2018-12-16 22:30:00+00:00 False\n",
      "2018-12-16 13:00:00-05:00\n",
      "2018-12-14 19:25:36.340856+00:00 2018-12-16 18:00:00+00:00 2018-12-16 22:30:00+00:00 False\n",
      "2018-12-16 13:00:00-05:00\n",
      "2018-12-14 19:25:36.340856+00:00 2018-12-16 18:00:00+00:00 2018-12-16 22:30:00+00:00 False\n",
      "2018-12-16 16:05:00-05:00\n",
      "2018-12-14 19:25:36.340856+00:00 2018-12-16 21:05:00+00:00 2018-12-17 01:35:00+00:00 False\n",
      "2018-12-16 16:25:00-05:00\n",
      "2018-12-14 19:25:36.340856+00:00 2018-12-16 21:25:00+00:00 2018-12-17 01:55:00+00:00 False\n",
      "2018-12-16 20:20:00-05:00\n",
      "2018-12-14 19:25:36.340856+00:00 2018-12-17 01:20:00+00:00 2018-12-17 05:50:00+00:00 False\n",
      "2018-12-17 20:15:00-05:00\n",
      "2018-12-14 19:25:36.340856+00:00 2018-12-18 01:15:00+00:00 2018-12-18 05:45:00+00:00 False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _last_game_ended_recently():\n",
    "    r = requests.get('http://www.nfl.com/liveupdate/scorestrip/ss.xml')\n",
    "    schedxml = BeautifulSoup(r.text, \"html.parser\")\n",
    "\n",
    "#    current_utc_ts = pytz.utc.localize(datetime(2018, 11, 5, 18, 59))\n",
    "    current_utc_ts = pytz.utc.localize(datetime.utcnow())\n",
    "    last_game_end_utc_ts = pytz.utc.localize(datetime(2000, 1, 1, 0, 0))\n",
    "    local_tz = pytz.timezone('US/Eastern')\n",
    "\n",
    "    for info in schedxml.findAll('g'):\n",
    "        hour, minute = info['t'].strip().split(':')\n",
    "        d = local_tz.localize(datetime(int(info['eid'][:4]), int(info['eid'][4:6]), int(info['eid'][6:8]),\n",
    "                              (int(hour) + 12) % 24, int(minute))) \n",
    "        print(d)\n",
    "        if(d.hour == 21 and d.minute == 30): #Saturday 9:30am games need to be adjusted from PM to AM\n",
    "            d = d - timedelta(hours=12)\n",
    "        \n",
    "        start_utc = d.astimezone(pytz.timezone('UTC')) #convert to UTC for AWS Lambda environment\n",
    "        end_utc = d.astimezone(pytz.timezone('UTC')) + timedelta(hours=4.5) #convert to UTC for AWS Lambda environment\n",
    "\n",
    "        print(current_utc_ts,start_utc,end_utc,current_utc_ts >= start_utc and current_utc_ts <= end_utc )\n",
    "        if(current_utc_ts >= start_utc and current_utc_ts <= end_utc):\n",
    "            return True        \n",
    "\n",
    "    return False\n",
    "\n",
    "_last_game_ended_recently()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def generate_charts():\n",
    "    data = table.scan()\n",
    "\n",
    "    df = json_normalize(data, 'Items')[['COLLECTTIMESTAMP','TEAM1','TEAM1NAME','TEAM1PTS','TEAM1PROJ','TEAM2NAME','TEAM2PTS','TEAM2PROJ','SCORINGPERIOD']]\n",
    "    df = df[df['SCORINGPERIOD']==week].sort_values('COLLECTTIMESTAMP', ascending=True)\n",
    "    #df[['COLLECTTIMESTAMP']] = df[['COLLECTTIMESTAMP']].apply(pd.to_datetime)  # commenting removes attempt at date labels on x-axis\n",
    "    df[['TEAM1PTS','TEAM1PROJ','TEAM2PTS','TEAM2PROJ']] = df[['TEAM1PTS','TEAM1PROJ','TEAM2PTS','TEAM2PROJ']].apply(pd.to_numeric)\n",
    "\n",
    "\n",
    "    imgs = []\n",
    "    for home_team in df['TEAM1NAME'].unique():\n",
    "        matchup = df[df['TEAM1NAME']==home_team]\n",
    "        team1 = matchup['TEAM1NAME'].unique()[0]\n",
    "        team2 = matchup['TEAM2NAME'].unique()[0]\n",
    "\n",
    "        fig, ax = plt.subplots(1,1)\n",
    "\n",
    "        plt.title(team1+' vs. '+team2+'\\nWeek '+week)\n",
    "        #ax.xaxis.set_minor_locator(md.HourLocator(interval=4))   # every 4 hours\n",
    "        #ax.xaxis.set_minor_formatter(md.DateFormatter('%H:%M'))  # hours and minutes\n",
    "        #ax.xaxis.set_major_locator(md.HourLocator(interval=12))    # every day\n",
    "        #ax.xaxis.set_major_formatter(md.DateFormatter('\\n%a'))\n",
    "        #ax.set_xlim(datetime(2018, 10, 1, 20), datetime(2018, 10, 2 , 0))\n",
    "        ax.xaxis.set_major_locator(plt.NullLocator())\n",
    "        \n",
    "        line_t1pts, = ax.plot(matchup['COLLECTTIMESTAMP'], matchup['TEAM1PTS'], 'r', label=matchup['TEAM1NAME'].unique()[0]+' PTS')\n",
    "        line_t1proj, = ax.plot(matchup['COLLECTTIMESTAMP'], matchup['TEAM1PROJ'], 'r',linestyle='--', dashes=(2, 2), label=matchup['TEAM1NAME'].unique()[0]+' PROJ')\n",
    "        line_t2pts, = ax.plot(matchup['COLLECTTIMESTAMP'], matchup['TEAM2PTS'], 'b', label=matchup['TEAM2NAME'].unique()[0]+' PTS')\n",
    "        line_t2proj, = ax.plot(matchup['COLLECTTIMESTAMP'], matchup['TEAM2PROJ'], 'b',linestyle='--', dashes=(2, 2), label=matchup['TEAM2NAME'].unique()[0]+' PROJ')\n",
    "        ax.legend(loc='best')\n",
    "\n",
    "        buf = io.BytesIO()\n",
    "        plt.savefig(buf, format='png')\n",
    "        buf.seek(0)\n",
    "        imgs.append(buf)\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "    return imgs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def post_to_groupme(input, imgs):\n",
    "    headers_img = {\n",
    "        'X-Access-Token': input['token'],\n",
    "        'Content-Type': 'image/jpeg',\n",
    "    }\n",
    "\n",
    "    headers_post = {\n",
    "        'Content-Type': 'application/json',\n",
    "    }\n",
    "\n",
    "    for img in imgs:\n",
    "        img.seek(0)\n",
    "        img = requests.post('https://image.groupme.com/pictures', headers=headers_img, data=img)\n",
    "        imgurl = img.json()['payload']['picture_url']\n",
    "        data = '{\"bot_id\":\"'+input['bot_id']+'\",\"text\":\"\",\"attachments\":[{\"type\":\"image\",\"url\":\"'+imgurl+'\"}]}'\n",
    "        response = requests.post('https://api.groupme.com/v3/bots/post', headers=headers_post, data=data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lambda_handler(input,context):\n",
    "    if not _is_nfl_game_active() and not _last_game_ended_recently():\n",
    "        return False\n",
    "    \n",
    "    post_to_groupme(input, generate_charts())\n",
    "    return True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#lambda_handler(params,None)\n",
    "#post_to_groupme(params, generate_charts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<_io.BytesIO at 0x111b4c620>,\n",
       " <_io.BytesIO at 0x111b4c938>,\n",
       " <_io.BytesIO at 0x111b4cbf8>,\n",
       " <_io.BytesIO at 0x111b4cfc0>,\n",
       " <_io.BytesIO at 0x1105ac1a8>,\n",
       " <_io.BytesIO at 0x1105ac468>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
