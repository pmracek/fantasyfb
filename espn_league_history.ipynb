{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, re, csv, espn\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import requests\n",
    "from collections import defaultdict\n",
    "import math\n",
    "\n",
    "seasons = range(2017,datetime.now().year+1)\n",
    "\n",
    "def outcome(score1, score2):\n",
    "        if score1 > score2:\n",
    "                outcome = 'W'\n",
    "        elif score1 < score2:\n",
    "                outcome = 'L'\n",
    "        else:\n",
    "                outcome = 'T'\n",
    "        return outcome\n",
    "\n",
    "teamidpattern = re.compile('teamId=(?P<id>\\d+)')\n",
    "weekpattern = re.compile('(?P<wktype>(WEEK|ROUND))\\s(?P<wknum>\\d+)')\n",
    "seasonidpattern = re.compile('seasonId=(?P<season>\\d+)')\n",
    "scoringperiodidpattern = re.compile('scoringPeriodId=(?P<id>\\d+)')\n",
    "bidresultpattern = re.compile('\\w+(?=\\.)')\n",
    "\n",
    "def class_not_leagueSettingsTable(tag):\n",
    "        return tag.has_attr('class') and not re.match(\"leagueSettingsTable\", ' '.join(tag['class'])) and re.match(\"tableBody\", ' '.join(tag['class']))  # have to use the ' '.join() syntax because tag['class'] is actually a list\n",
    "\n",
    "def class_playertablebody(tag):\n",
    "    return tag.has_attr('class') and re.match(\"playerTableTable\", ' '.join(tag['class']))  # have to use the ' '.join() syntax because tag['class'] is actually a list\n",
    "\n",
    "def class_playerrow(tag):\n",
    "    return tag.has_attr('class') and re.match(\"pncPlayerRow\", ' '.join(tag['class']))  # have to use the ' '.join() syntax because tag['class'] is actually a list\n",
    "\n",
    "def get_week_formatted(wk):\n",
    "    weekpattern = re.compile('(?P<wktype>(WEEK|ROUND))\\s(?P<wknum>\\d+)', flags=re.IGNORECASE)\n",
    "    wktype = weekpattern.search(wk).group('wktype')\n",
    "    wknum = weekpattern.search(wk).group('wknum')\n",
    "    return wknum if wktype.upper() == \"WEEK\" else \"P\"+wknum\n",
    "\n",
    "def save_file(season,wk,file,data):\n",
    "    with open('data/'+str(season)+'_'+str(wk)+'_'+str(file)+'.txt', 'w', newline = '\\n') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerows(data)\n",
    "\n",
    "nfl_start_dt = {\n",
    "        2008:datetime.strptime('20080901','%Y%m%d').date() \n",
    "        , 2009:datetime.strptime('20090907','%Y%m%d').date() \n",
    "        , 2010:datetime.strptime('20100906','%Y%m%d').date() \n",
    "        , 2011:datetime.strptime('20110905','%Y%m%d').date() \n",
    "        , 2012:datetime.strptime('20120903','%Y%m%d').date() \n",
    "        , 2013:datetime.strptime('20130902','%Y%m%d').date() \n",
    "        , 2014:datetime.strptime('20140901','%Y%m%d').date() \n",
    "        , 2015:datetime.strptime('20150907','%Y%m%d').date() \n",
    "        , 2016:datetime.strptime('20160905','%Y%m%d').date() \n",
    "        , 2017:datetime.strptime('20170904','%Y%m%d').date()\n",
    "       }\n",
    "\n",
    "def week_of_season(d):    \n",
    "    s = datetime.strptime(d,'%Y%m%d').year\n",
    "    dt = datetime.strptime(d,'%Y%m%d').date()\n",
    "\n",
    "    return math.ceil((dt - nfl_start_dt[s]).days/7)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo figure out how to load teams / years dynamically\n",
    "pre2010 = {'1':'Scott', '2':'Brent', '3':'JMT', '4':'JJ', '5':'Tim', '6':'Jeremy', '7':'Kyle', '8':'Thomas', '9':'Schwartz', '10':'Blackwell'}\n",
    "t2010 = {'1':'Scott', '2':'Brent', '3':'JMT', '4':'JJ', '5':'Tim', '6':'Jeremy', '7':'Kyle', '8':'Thomas', '9':'Schwartz', '10':'Blackwell', '11':'Tony', '12':'Doogs'}\n",
    "t2011 = {'1':'Scott', '2':'Brent', '3':'JMT', '4':'JJ', '5':'Tim', '6':'Jeremy', '7':'Kyle', '8':'Thomas', '9':'Schwartz', '10':'Blackwell', '11':'Tony', '12':'JonBurriss'}\n",
    "t2012 = {'1':'Scott', '2':'Brent', '3':'JMT', '4':'JJ', '5':'Tim', '6':'Jeremy', '7':'Kyle', '8':'Thomas', '9':'Schwartz', '10':'Blackwell', '11':'Tony', '12':'Paul'}\n",
    "t2016 = {'1':'Scott', '2':'Brent', '3':'JMT', '4':'JJ', '5':'Tim', '6':'Jeremy', '7':'Kyle', '8':'Thomas', '9':'Schwartz', '10':'Goss', '11':'Tony', '12':'Paul'}\n",
    "\n",
    "teams = {2008:pre2010, 2009:pre2010, 2010:t2010, 2011:t2011, 2012:t2012, 2013:t2012, 2014:t2012, 2015:t2012, 2016:t2016, 2017:t2016, 2018:t2016}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Selenium webdriver for Chrome & Login \n",
    "##### Originally used Requests but ESPN site redesign broke login form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = espn.getsession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##  Create and Parse Soups for Weekly Team Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2017\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 P1 P2 \n",
      "2018\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 P1 P2 "
     ]
    }
   ],
   "source": [
    "quickboxurls = defaultdict(list)\n",
    "\n",
    "for season in seasons:\n",
    "        \n",
    "        print('')\n",
    "        print(season)\n",
    "        \n",
    "        ### Build matchup_recaps\n",
    "        results = [('SEASON','SCORINGPERIOD', 'WEEK_NM','TEAM','TEAMNAME','SCORE','OPPONENT','OPPONENTNAME','OPPONENTSCORE', 'OUTCOME')]\n",
    "        url = 'http://games.espn.go.com/ffl/schedule?leagueId=111414&seasonId='+str(season)\n",
    "        r = s.post(url)\n",
    "        cur_season = BeautifulSoup(r.text, \"lxml\")\n",
    "        \n",
    "        first_row = True\n",
    "        while True:\n",
    "                if first_row:\n",
    "                        current_row = cur_season.find(class_not_leagueSettingsTable).tr\n",
    "                        first_row = False\n",
    "                else:\n",
    "                        current_row = current_row.next_sibling\n",
    "                \n",
    "                if current_row is None: # Past last row; exit\n",
    "                        break\n",
    "                if current_row == '\\n': # Line feed, do not process\n",
    "                        continue\n",
    "\n",
    "                try:    # this try block must come before the raw_score or else week never gets set.\n",
    "                        class_ = current_row['class']\n",
    "                except KeyError:\n",
    "                        class_ = \"\"\n",
    "                \n",
    "                if 'tableSubHead' in class_:    # Header row, do not process\n",
    "                        continue\n",
    "                if 'tableHead' in class_:       # Weekly header.  Grab week # and move on\n",
    "                        week = get_week_formatted(current_row.td.text)\n",
    "                        print(week, end=\" \")\n",
    "                        continue\n",
    "\n",
    "                try:\n",
    "                        raw_score = current_row.contents[11].text.rstrip('*')\n",
    "                        \n",
    "                        if raw_score == 'Preview' or raw_score == 'Box':      # Game has not been played yet\n",
    "                                continue        \n",
    "                except IndexError:      # Spacer row\n",
    "                        continue\n",
    "                        \n",
    "                                \n",
    "                quickboxurls[season].append('http://games.espn.com'+current_row.contents[11].a['href'])  \n",
    "                scoringperiod = scoringperiodidpattern.search(current_row.contents[11].a['href']).group('id')\n",
    "                        \n",
    "                team1 = teamidpattern.search(current_row.contents[1].a.get('href')).group('id')         \n",
    "                team1score = float(raw_score.split('-')[0])\n",
    "                \n",
    "                team2 = teamidpattern.search(current_row.contents[7].a.get('href')).group('id')\n",
    "                team2score = float(raw_score.split('-')[1])     \n",
    "                \n",
    "                results.append((season, scoringperiod, week, team1, teams[int(season)][team1], team1score, team2, teams[int(season)][team2], team2score, outcome(team1score, team2score)))\n",
    "                results.append((season, scoringperiod, week, team2, teams[int(season)][team2], team2score, team1, teams[int(season)][team1], team1score, outcome(team2score, team1score)))\n",
    "\n",
    "        save_file(season,'00','matchup_recap',results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2017\n",
      "\n",
      "2018\n"
     ]
    }
   ],
   "source": [
    "for season in seasons:\n",
    "    print('')\n",
    "    print(season)\n",
    "    \n",
    "    boxresults = [('SEASON','SCORINGPERIOD', 'WEEK_NM','TEAM','TEAMNAME','SLOT','PLAYERID','PLAYERNAME','PLAYEROPP','GAMEOUTCOME', 'PLAYERPOINTS', 'STARTERPOINTS', 'BENCHPOINTS')]\n",
    "    for quickboxurl in quickboxurls[season]:        \n",
    "        r = s.post(quickboxurl)\n",
    "        cur_matchup = BeautifulSoup(r.text, \"lxml\")\n",
    "\n",
    "        scoringperiod = scoringperiodidpattern.search(quickboxurl).group('id')\n",
    "        week = get_week_formatted(cur_matchup.select('.games-pageheader')[0].em.text)\n",
    "\n",
    "        allscores = cur_matchup.select('.playertableTableHeader') # Grab the table header with team name because the class=playerTable is used for both bench and starters.  Aka get double results. \n",
    "        for box in allscores:    \n",
    "            cur_team_box = box.parent.parent\n",
    "            left_or_right_box = 0 if re.search('left',cur_team_box['style'],re.IGNORECASE) else 1\n",
    "\n",
    "            cur_team_id = teamidpattern.search(cur_matchup.find(id='teamInfos').find_all('a')[left_or_right_box].get('href')).group('id')\n",
    "\n",
    "            if int(season) > 2015:\n",
    "                starterpts = cur_team_box.select('.totalScore')[0].text\n",
    "            else:\n",
    "                starterpts = cur_team_box.select('.playerTableBgRowTotals')[0].select('.appliedPoints')[0].text\n",
    "            try: \n",
    "                benchpts = cur_matchup.find(id='tmInactivePts_'+str(cur_team_id)).text \n",
    "            except:\n",
    "                benchpts = '0'\n",
    "\n",
    "            players = cur_team_box.select('.pncPlayerRow')\n",
    "            for player in players:  # will be iterable\n",
    "                slot = player.select('.playerSlot')[0].text if int(season) > 2015 else player.select('.playertablePlayerName')[0].text.split()[-1]\n",
    "                if slot.upper() == 'IR' or player.select('td')[1].text.strip()=='':\n",
    "                    break\n",
    "                playerid = player.find('a')['playerid'] if int(season) > 2015 else 'null'\n",
    "                playername = player.find('a').text if int(season) > 2015 and player.select('td')[1].text.strip()!='' else player.select('.playertablePlayerName')[0].text\n",
    "                if re.search('BYE', player.select('.playertablePlayerName')[0].next_sibling.text, re.IGNORECASE):\n",
    "                    playeropp = 'BYE'\n",
    "                    gameoutcome = 'BYE'\n",
    "                else:\n",
    "                    playeropp = player.select('.playertablePlayerName')[0].next_sibling.text if int(season) > 2015 else player.find_all('a')[0].text\n",
    "                    gameoutcome = player.select('.gameStatusDiv')[0].text[2:] if int(season) > 2015 else player.find_all('a')[1].text\n",
    "                playerpoints = player.select('.playertableStat')[0].text\n",
    "\n",
    "                boxresults.append((season, scoringperiod, week, cur_team_id, teams[int(season)][cur_team_id],slot, playerid, playername, playeropp, gameoutcome, playerpoints, starterpts, benchpts))\n",
    "\n",
    "    save_file(season,'00','quickbox',boxresults)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2017\n",
      "0\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "for season in seasons: \n",
    "    print('')\n",
    "    print(season)\n",
    "    if season < 2016:\n",
    "        break\n",
    "        \n",
    "    url = 'http://games.espn.go.com/ffl/waiverreport?leagueId=111414&seasonId='+str(season)\n",
    "    r = s.post(url)\n",
    "    auction_landing_page = BeautifulSoup(r.text, \"lxml\")\n",
    "\n",
    "    scoringPeriodId = 0\n",
    "    bids = [('SEASON','SCORINGPERIOD','WEEK_NM','AUCTIONDATE','TEAM','TEAMNAME','PLAYERID','PLAYERNAME','BID','BIDRESULT')]\n",
    "    \n",
    "    for option in auction_landing_page.find_all('option'):\n",
    "        auction_date = option.get('value')\n",
    "        \n",
    "        if scoringPeriodId != week_of_season(auction_date) and len(bids) > 1:\n",
    "            print(scoringPeriodId)\n",
    "            save_file(season,'{0:02d}'.format(scoringPeriodId),'faab_report',bids)                \n",
    "            bids = [('SEASON','SCORINGPERIOD','WEEK_NM','AUCTIONDATE','TEAM','TEAMNAME','PLAYERID','PLAYERNAME','BID','BIDRESULT')]\n",
    "        \n",
    "        scoringPeriodId = week_of_season(auction_date)         \n",
    "        url = 'http://games.espn.go.com/ffl/waiverreport?leagueId=111414&seasonId='+str(season)+'&date='+auction_date\n",
    "        r = s.post(url)\n",
    "        cur_auction = BeautifulSoup(r.text, \"lxml\")   \n",
    "        \n",
    "        bidTbl = cur_auction.find_all('tr', attrs={'class':'tableBody'})\n",
    "        for bid in bidTbl:\n",
    "            owner = bid.contents[2].a\n",
    "            teamId = teamidpattern.search(owner.get('href')).group('id')\n",
    "            player = bid.contents[4].a\n",
    "            bidAmt = bid.contents[6].string.lstrip('$')\n",
    "            bidResult = bidresultpattern.search(bid.contents[7].text).group()\n",
    "            \n",
    "            bids.append((season,week_of_season(auction_date),week_of_season(auction_date), auction_date , teamId , teams[int(season)][teamId], player.get('playerid') , player.string , bidAmt , bidResult))\n",
    "\n",
    "    #last week each season will not be saved yet\n",
    "    save_file(season,'{0:02d}'.format(scoringPeriodId),'faab_report',bids)\n",
    "    print(scoringPeriodId)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
